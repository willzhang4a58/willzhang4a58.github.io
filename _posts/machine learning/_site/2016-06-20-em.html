<ul id="markdown-toc">
  <li><a href="#gibbs-inequality" id="markdown-toc-gibbs-inequality">1. Gibbs Inequality</a></li>
  <li><a href="#description-of-em" id="markdown-toc-description-of-em">2. Description of EM</a></li>
  <li><a href="#proof" id="markdown-toc-proof">3. Proof</a></li>
</ul>

<h2 id="gibbs-inequality">1. Gibbs Inequality</h2>

<p>自然对数满足</p>

<p>\begin{align}
&amp; \ln x \leq x - 1 \\
&amp;s.t. \quad x&gt;0
\end{align}</p>

<p>仅当<script type="math/tex">x=1</script>时等式成立</p>

<p>有两个概率分布
\begin{align}
P = \{p_1,p_2,…,p_n\} \\
Q = \{q_1,q_2,…,q_n\}
\end{align}</p>

<p>结合上面的不等式，有</p>

<p>\begin{align}
-\sum_{i=1}^n p_i\ln \frac{q_i}{p_i} &amp;\geq -\sum_{i=1}^np_i(\frac{q_i}{p_i}-1) \\
&amp;= \sum_{i=1}^n(p_i - q_i) \\
&amp;= 0
\end{align}</p>

<p>整理上式得到最终的Gibbs Inequality</p>

<p>\begin{align}
-\sum_{i=1}^n p_i\ln p_i  \leq -\sum_{i=1}^n p_i\ln q_i
\end{align}</p>

<h2 id="description-of-em">2. Description of EM</h2>

<p>存在一个统计模型，其参数为<script type="math/tex">\theta</script>，可以生成可观测到的数据集合<script type="math/tex">X</script>，以及不可观测的数据集合<script type="math/tex">Z</script>，其<script type="math/tex">\theta</script>的似然函数为</p>

<p>\begin{align}
L(\theta;X) = p(X|\theta) = \sum_Zp(X,Z|\theta)
\end{align}</p>

<p>当<script type="math/tex">Z</script>的取值范围很大时，上式的计算代价非常大，因此有迭代的EM方法</p>

<p><strong>Expectation Step</strong></p>

<p>给定当前的<script type="math/tex">\theta</script>的估计值<script type="math/tex">\theta^{(t)}</script>，给定X，计算当前对数似然函数的期望
\begin{align}
Q(\theta|\theta^{(t)}) = E_{Z|X,\theta^{(t)}}L(\theta;X,Z) = \sum_Zp(Z|X,\theta^{(t)})\log p(X,Z|\theta)
\end{align}</p>

<p><strong>Maximization Step</strong></p>

<p>\begin{align}
\theta^{(t+1)}= \mathop{argmax}_{\theta}Q(\theta|\theta^{(t)})
\end{align}</p>

<h2 id="proof">3. Proof</h2>

<p>根据贝叶斯定理
\begin{align}
\log p(X|\theta)=\log p(X,Z|\theta) - \log p(Z|X,\theta)
\end{align}</p>

<p>等式两边同时乘以<script type="math/tex">p(Z \vert X,\theta^{(t)})</script>，并对<script type="math/tex">Z</script>求和</p>

<p>\begin{align}
\log p(X|\theta)&amp;=\sum_Zp(Z|X,\theta^{(t)})\log p(X,Z|\theta) - \sum_Zp(Z|X,\theta^{(t)})\log p(Z|X,\theta) \\
&amp;= Q(\theta|\theta^{(t)})- \sum_Zp(Z|X,\theta^{(t)})\log p(Z|X,\theta)
\end{align}</p>

<p>为了符号简洁，定义</p>

<p>\begin{align}
H(\theta|\theta^{(t)}) = - \sum_Zp(Z|X,\theta^{(t)})\log p(Z|X,\theta)
\end{align}</p>

<p>于是</p>

<p>\begin{align}
\log p(X|\theta) = Q(\theta|\theta^{(t)}) + H(\theta|\theta^{(t)})
\end{align}</p>

<p>由于</p>

<p>\begin{align}
diff &amp;=\log p(X|\theta^{(t+1)}) - \log p(X|\theta^{(t)}) \\ 
&amp;=  Q(\theta^{(t+1)}|\theta^{(t)})-Q(\theta^{(t)}|\theta^{(t)}) + H(\theta^{(t+1)}|\theta^{(t)})-H(\theta^{(t)}|\theta^{(t)}) \\
&amp;= Q_{diff} + H_{diff}
\end{align}</p>

<p>由于<script type="math/tex">\theta^{t+1}</script>的定义
\begin{align}
Q_{diff}&amp;=Q(\theta^{(t+1)}|\theta^{(t)})-Q(\theta^{(t)}|\theta^{(t)}) \geq 0
\end{align}</p>

<p>由于Gibbs Inequality</p>

<p>\begin{align}
H_{diff} &amp;= H(\theta^{(t+1)}|\theta^{(t)})-H(\theta^{(t)}|\theta^{(t)})  \\
&amp;= - \sum_Zp(Z|X,\theta^{(t)})\log p(Z|X,\theta^{t+1}) + \sum_Zp(Z|X,\theta^{(t)})\log p(Z|X,\theta^{(t)}) \\
&amp;\geq 0
\end{align}</p>

<p>因此</p>

<p>\begin{align}
\log p(X|\theta^{(t+1)}) \geq \log p(X|\theta^{(t)})
\end{align}</p>

<p>至此，EM算法的正确性得以证明</p>
