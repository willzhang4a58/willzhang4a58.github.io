<ul id="markdown-toc">
  <li><a href="#generative-model" id="markdown-toc-generative-model">1. Generative model</a></li>
  <li><a href="#the-collapsed-lda-gibbs-sampler" id="markdown-toc-the-collapsed-lda-gibbs-sampler">2. The collapsed LDA Gibbs sampler</a>    <ul>
      <li><a href="#the-joint-distribution" id="markdown-toc-the-joint-distribution">2.1 The joint distribution</a></li>
      <li><a href="#full-conditional" id="markdown-toc-full-conditional">2.2 Full conditional</a></li>
      <li><a href="#multinomial-parameters" id="markdown-toc-multinomial-parameters">2.3 Multinomial parameters</a></li>
    </ul>
  </li>
</ul>

<h2 id="generative-model">1. Generative model</h2>

<p>LDA的贝叶斯网络表示</p>

<p><img src="https://upload.wikimedia.org/wikipedia/commons/4/4d/Smoothed_LDA.png" alt="" /></p>

<p>符号意思为</p>

<ul>
  <li><script type="math/tex">M</script>：文档数量</li>
  <li><script type="math/tex">V</script>：所有文档出现的词组成的词表的大小</li>
  <li><script type="math/tex">N</script>：总词数，为所有文档的词数的总和</li>
  <li><script type="math/tex">K</script>：主题数量</li>
  <li><script type="math/tex">d</script>：文档，<script type="math/tex">d_m</script>表示第<script type="math/tex">m</script>篇文档</li>
  <li><script type="math/tex">w</script>：词，<script type="math/tex">w_{m,n}</script>表示<script type="math/tex">d_m</script>的第<script type="math/tex">n</script>个词，<script type="math/tex">w_m</script>表示<script type="math/tex">d_m</script>的<script type="math/tex">N_d</script>个词</li>
  <li><script type="math/tex">z</script>：主题，<script type="math/tex">z_k</script>表示第<script type="math/tex">k</script>个主题</li>
  <li><script type="math/tex">W</script>：所有文档的所有词组成的<script type="math/tex">N</script>维向量</li>
  <li><script type="math/tex">Z</script>：所有文档的所有词对应的主题组成的<script type="math/tex">N</script>维向量</li>
  <li><script type="math/tex">\theta</script>：<script type="math/tex">\theta_m</script>为多项式分布<script type="math/tex">p(z\vert d_m)</script>的参数，<script type="math/tex">\theta_{m,k}</script>表示<script type="math/tex">p(z_k\vert d_m)</script></li>
  <li><script type="math/tex">\Theta</script>：<script type="math/tex">\Theta=\left\{ \theta_1,\theta_2,...,\theta_M \right\}</script></li>
  <li><script type="math/tex">\alpha</script>：<script type="math/tex">\theta</script>的先验分布（Dirichlet分布）的参数</li>
  <li><script type="math/tex">\varphi</script>：<script type="math/tex">\varphi_k</script>为多项式分布<script type="math/tex">p(w\vert z_k)</script>的参数，<script type="math/tex">\varphi_{k,t}</script>表示<script type="math/tex">p(w_t\vert z_k)</script></li>
  <li><script type="math/tex">\Phi</script>：<script type="math/tex">\Phi = \left\{ \varphi_1,\varphi_2,...,\varphi_K \right\}</script></li>
  <li><script type="math/tex">\beta</script>：<script type="math/tex">\varphi</script>的先验分布（Dirichlet分布）的参数</li>
</ul>

<h2 id="the-collapsed-lda-gibbs-sampler">2. The collapsed LDA Gibbs sampler</h2>

<h3 id="the-joint-distribution">2.1 The joint distribution</h3>

<p>在LDA中，由贝叶斯网络可以得到如下分解</p>

<p>\begin{align}
p(W,Z\vert \alpha,\beta)=p(W\vert Z,\beta)p(Z\vert \alpha)
\end{align}</p>

<p>为了符号简洁，定义</p>

<p>\begin{align}
\Delta (\alpha) = \frac{\prod_{i}\Gamma(\alpha_i)}{\Gamma(\sum_i\alpha_i)}
\end{align}</p>

<p>上式中的第一项进行化简</p>

<p>\begin{align}
p(W\vert Z,\beta) &amp;=\int p(W\vert Z,\Phi)p(\Phi\vert \beta)d\Phi \\
&amp;= \int p(\Phi\vert \beta)\prod_{k=1}^K\prod_{t=1}^V\varphi_{k,t}^{n_{k,t}}d\Phi \\
&amp;= \prod_{k=1}^K\frac{\Delta(n_k+\beta)}{\Delta \beta},\quad n_k={n_{k,t}}_{t=1}^V
\end{align}</p>

<p>化简第二项</p>

<p>\begin{align}
p(Z\vert \alpha)&amp;=\int p(Z\vert \Theta)p(\Theta\vert \alpha)d\Theta \\
&amp;=\int p(\Theta\vert \alpha)\prod_{m=1}^M\prod_{k=1}^K\theta_{m,k}^{n_{m,k}}d\Theta \\
&amp;=\prod_{m=1}^M\frac{\Delta(n_m+\alpha)}{\Delta(\alpha)},\quad n_m={n_{m,k}}_{k=1}^K
\end{align}</p>

<p>于是联合概率分布为</p>

<p>\begin{align}
p(Z,W\vert \alpha,\beta)=\prod_{k=1}^K\frac{\Delta(n_k+\beta)}{\Delta \beta}\prod_{m=1}^M\frac{\Delta(n_m+\alpha)}{\Delta(\alpha)}
\end{align}</p>

<h3 id="full-conditional">2.2 Full conditional</h3>

<p>令<script type="math/tex">W_i</script>表示第<script type="math/tex">m</script>篇文档的第<script type="math/tex">n</script>个词
求<script type="math/tex">p(Z_i\vert Z_{\neg i},W)</script></p>

<p>\begin{align}
p(Z_i=k\vert Z_{\neg i},W)&amp;=\frac{p(W,Z)}{p(W,Z_{\neg i})} \\
&amp;=\frac{p(W\vert Z)}{p(W_{\neg i}\vert Z_{\neg i})p(W_i)}\frac{p(Z)}{p(Z_{\neg i})} \\
&amp;\propto \frac{\Delta(n_k+\beta)}{\Delta(n_{k,\neg i}+\beta)}\frac{\Delta(n_m+\alpha)}{\Delta(n_{m,\neg i} + \alpha)} 
\end{align}</p>

<p>不断进行采样，即可得到<script type="math/tex">Z</script></p>

<h3 id="multinomial-parameters">2.3 Multinomial parameters</h3>

<p>最后我们需要得到<script type="math/tex">\Theta</script>和<script type="math/tex">\Phi</script></p>

<p>\begin{align}
p({\theta}_m\vert {\alpha},W,Z)&amp;=\frac{1}{Norm}\prod_{n=1}^{N_m}p(Z_{m,n}\vert {\theta}_m)p({\theta}_m\vert {\alpha})=Dir({\theta}_m\vert {n}_m+{\alpha}) \\
p({\varphi}_k\vert {\beta},W,Z)&amp;=\frac{1}{Norm}\prod_{i:Z_i=k}p(W_i\vert {\varphi}_k)p({\varphi}_k\vert {\beta})=Dir({\varphi}_k\vert {n}_k+{\beta})
\end{align}</p>

<p>容易发现，这个结果使得在线学习非常容易
使用Dirichlet分布的期望就是最后的结果了</p>
