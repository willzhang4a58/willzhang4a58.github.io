<ul id="markdown-toc">
  <li><a href="#ucb" id="markdown-toc-ucb">1. UCB</a></li>
  <li><a href="#linucb" id="markdown-toc-linucb">2. LinUCB</a></li>
</ul>

<h2 id="ucb">1. UCB</h2>

<p><a href="/2016/05/16/mab">上一篇文章</a>中介绍了一种context-free的方法，<script type="math/tex">\epsilon-greedy</script>。</p>

<p>其能够很好地完成对未知商品的exploration，同时完成对奖励的exploitation。</p>

<p>但是在后期，假如所有的商品都已经探索完毕，并且没有新商品加进来</p>

<p>显然此时并不需要做exploration，<script type="math/tex">\epsilon</script>概率对应部分的奖励就拿不到了</p>

<p>在此，介绍一种新的方法，Upper Confidence Bound</p>

<p>这里仅简单介绍一下基本思想</p>

<p>假如有一个老虎机，玩了10次，奖励是2，那么可以认为其奖励均值是2，此时设定其均值的95%置信区间为[0,4]</p>

<p>而另一个老虎机，玩了100词，奖励均值是3，那么可以设定其均值的95%置信区间为[2.9,3.1]</p>

<p>UCB在此时的决策是选择置信区间上界最大的一个老虎机</p>

<p>很容易发现</p>

<ul>
  <li>对于未知商品，尽管其均值可能很低，但是由于其不确定性会导致置信区间的上界会很大，从而触发exploration</li>
  <li>对于已经很熟悉的商品，如果其均值很高，会触发exploitation</li>
</ul>

<p>UCB的难点在于如何设定置信上界，设定方法有很多种，这里不介绍</p>

<p>设定的方法通常会满足如下性质</p>

<ul>
  <li>随着迭代轮数的增长，上界会远离均值</li>
  <li>随着被选择次数的增长，上界会靠近均值</li>
</ul>

<h2 id="linucb">2. LinUCB</h2>

<p><a href="/2016/05/16/mab">上一篇文章</a>中提到了Contextual Bandit，在Multi-Armed Bandit的基础上每次做决策时还会有一个特征向量</p>

<p>LinUCB是处理Contextual Bandit的一个方法，在LinUCB中，设定</p>

<p>\begin{align}
E\left[r_{t,a}|x_{t,a}\right] = x_{t,a}^T\theta_a
\end{align}</p>

<p><script type="math/tex">\theta_a</script>是LinUCB模型的参数，维度为<script type="math/tex">d</script></p>

<p>每个arm维护一个<script type="math/tex">\theta_a</script></p>

<p>对于单个arm，以其前m个context向量为行向量组成的矩阵称为<script type="math/tex">D_a</script></p>

<p>前m个reward组成的向量称为<script type="math/tex">c_a</script></p>

<p>使用<a href="/2016/05/18/ridge-regression/">ridge regression</a>，可以得到<script type="math/tex">\theta_a</script>的概率分布为高斯分布</p>

<p>\begin{align}
\theta_a \sim N \left((D_a^TD_a + I)^{-1}D_a^Tc_a, (D_a^TD_a + I)^{-1}\right)
\end{align}</p>

<p>为了符号简洁，令</p>

<p>\begin{align}
\hat{\theta}_a &amp;= (D_a^TD_a + I)^{-1}D_a^Tc_a \\
A_a &amp;= D_a^TD_a + I
\end{align}</p>

<p>于是<script type="math/tex">\theta_a</script>的概率分布可表示为<script type="math/tex">\theta_a \sim N(\hat{\theta}_a, A_a^{-1})</script></p>

<p>于是在第t次时可以得到<script type="math/tex">x_{t,a}^T\theta_a \sim N(x_{t,a}^T\hat{\theta}_a, x_{t,a}^TA_a^{-1}x_{t,a})</script>，也就是<script type="math/tex">r_{t,a} \sim N(x_{t,a}^T\hat{\theta}_a, x_{t,a}^TA_a^{-1}x_{t,a})</script></p>

<p>根据高斯分布的性质，得到置信上界后就可以使用普通UCB规则了</p>

<p>需要注意的是，<script type="math/tex">A_a与D_a^Tc_a</script>可以增量更新，于是标准流程如下</p>

<ul>
  <li>设定<script type="math/tex">\alpha</script></li>
  <li>For t = 1,2,3,…
    <ul>
      <li>对所有的arm获得本次的context向量</li>
      <li>For all <script type="math/tex">a</script>
        <ul>
          <li>if <script type="math/tex">a</script> is new
            <ul>
              <li>设置<script type="math/tex">A_a</script>为单位矩阵</li>
              <li>设置<script type="math/tex">b_a</script>为<script type="math/tex">d</script>维0零向量</li>
            </ul>
          </li>
          <li>计算<script type="math/tex">\hat{\theta}_a = A_a^{-1}b_a</script></li>
          <li>计算上界</li>
        </ul>
      </li>
      <li>选择最大上界对应的arm即<script type="math/tex">a_t</script>，并得到对应的<script type="math/tex">r_t</script></li>
      <li>更新<script type="math/tex">A_{a_t} = A_{a_t} + x_{t,a_t}x_{t,a_t}^T</script></li>
      <li>更新<script type="math/tex">b_{a_t} = b_{a_t} + r_tx_{t,a_t}</script></li>
    </ul>
  </li>
</ul>

